# -*- coding: utf-8 -*-
"""reddit_sentiment_analysis_on_us_tariffs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Alejog20/60f1cc45bb56e106fdf67f7250e03bd0/reddit_sentiment_analysis_on_us_tariffs.ipynb
"""

import requests
import pandas as pd
import datetime
import time
import re
import csv
import json
import base64
from urllib.parse import quote

def get_reddit_token(client_id, client_secret):
    """
    Obtiene un token de autenticaciÃ³n de Reddit usando OAuth

    Args:
        client_id (str): ID de cliente de la API de Reddit
        client_secret (str): Secret de cliente de la API de Reddit

    Returns:
        str: Token de acceso o None si falla
    """
    auth = base64.b64encode(f"{client_id}:{client_secret}".encode()).decode()
    headers = {
        "Authorization": f"Basic {auth}",
        "User-Agent": "ArancelesAnalysis/1.0"
    }
    data = {
        "grant_type": "client_credentials"
    }

    try:
        response = requests.post(
            "https://www.reddit.com/api/v1/access_token",
            headers=headers,
            data=data
        )

        if response.status_code == 200:
            return response.json().get("access_token")
        else:
            print(f"âŒ Error obteniendo token: {response.status_code}")
            print(f"Respuesta: {response.text}")
            return None
    except Exception as e:
        print(f"âŒ Error en la solicitud de token: {e}")
        return None

def search_reddit(token, query, subreddit, limit=25, sort="relevance"):
    """
    Busca posts en Reddit usando la API REST

    Args:
        token (str): Token de acceso OAuth
        query (str): TÃ©rmino de bÃºsqueda
        subreddit (str): Subreddit o 'all' para todos
        limit (int): NÃºmero mÃ¡ximo de resultados
        sort (str): MÃ©todo de ordenaciÃ³n (relevance, hot, new, top)

    Returns:
        list: Lista de posts encontrados
    """
    headers = {
        "Authorization": f"Bearer {token}",
        "User-Agent": "ArancelesAnalysis/1.0"
    }

    encoded_query = quote(query)

    if subreddit.lower() == 'all':
        url = f"https://oauth.reddit.com/search?q={encoded_query}&sort={sort}&limit={limit}"
    else:
        url = f"https://oauth.reddit.com/r/{subreddit}/search?q={encoded_query}&sort={sort}&restrict_sr=1&limit={limit}"

    try:
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            data = response.json()
            return data.get("data", {}).get("children", [])
        else:
            print(f"âŒ Error en la bÃºsqueda: {response.status_code}")
            print(f"Respuesta: {response.text}")
            return []
    except Exception as e:
        print(f"âŒ Error en la solicitud de bÃºsqueda: {e}")
        return []

def get_comments(token, post_id, limit=25):
    """
    Obtiene los comentarios de un post especÃ­fico

    Args:
        token (str): Token de acceso OAuth
        post_id (str): ID del post
        limit (int): NÃºmero mÃ¡ximo de comentarios

    Returns:
        list: Lista de comentarios
    """
    headers = {
        "Authorization": f"Bearer {token}",
        "User-Agent": "ArancelesAnalysis/1.0"
    }

    url = f"https://oauth.reddit.com/comments/{post_id}?limit={limit}"

    try:
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            data = response.json()
            if len(data) >= 2:  # El segundo elemento contiene los comentarios
                return data[1].get("data", {}).get("children", [])
            return []
        else:
            print(f"âŒ Error obteniendo comentarios: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ Error en la solicitud de comentarios: {e}")
        return []

def extract_reddit_data(client_id, client_secret, search_terms, subreddits, post_limit=25, comment_limit=25):
    """
    Extrae datos de Reddit basados en tÃ©rminos de bÃºsqueda y subreddits
    usando requests en lugar de PRAW

    Args:
        client_id (str): ID de cliente de la API de Reddit
        client_secret (str): Secret de cliente de la API de Reddit
        search_terms (list): Lista de tÃ©rminos a buscar
        subreddits (str): Subreddits donde buscar, separados por +
        post_limit (int): NÃºmero mÃ¡ximo de posts a extraer por tÃ©rmino
        comment_limit (int): NÃºmero mÃ¡ximo de comentarios por post

    Returns:
        tuple: DataFrames de posts y comentarios
    """
    # Obtener token de autenticaciÃ³n
    token = get_reddit_token(client_id, client_secret)
    if not token:
        print("âŒ No se pudo obtener el token de autenticaciÃ³n. Verifica tus credenciales.")
        return pd.DataFrame(), pd.DataFrame()

    print("âœ… AutenticaciÃ³n exitosa en Reddit API")

    all_posts = []
    all_comments = []
    comment_id = 0
    subreddit_list = subreddits.split('+')

    # Procesa cada tÃ©rmino de bÃºsqueda
    for term in search_terms:
        for subreddit in subreddit_list:
            print(f"ğŸ” Buscando '{term}' en r/{subreddit}")

            posts = search_reddit(token, term, subreddit, limit=post_limit)

            for post_data in posts:
                post = post_data.get("data", {})

                # Extrae informaciÃ³n del post
                post_id = post.get("id")

                # Evita duplicados
                if any(p.get("post_id") == post_id for p in all_posts):
                    continue

                # Extrae datos del post
                post_info = {
                    "post_id": post_id,
                    "title": post.get("title", ""),
                    "text": post.get("selftext", ""),
                    "score": post.get("score", 0),
                    "upvote_ratio": post.get("upvote_ratio", 0),
                    "created_utc": datetime.datetime.fromtimestamp(post.get("created_utc", 0)),
                    "num_comments": post.get("num_comments", 0),
                    "permalink": f"https://www.reddit.com{post.get('permalink', '')}",
                    "subreddit": post.get("subreddit", ""),
                    "author": post.get("author", "[deleted]"),
                    "search_term": term
                }

                all_posts.append(post_info)

                # Obtiene comentarios
                if post.get("num_comments", 0) > 0:
                    comments = get_comments(token, post_id, limit=comment_limit)

                    for comment_data in comments:
                        comment = comment_data.get("data", {})

                        # Ignora entradas que no son comentarios reales
                        if comment.get("body") is None or comment.get("id") is None:
                            continue

                        comment_info = {
                            "comment_id": comment_id,
                            "post_id": post_id,
                            "text": comment.get("body", ""),
                            "score": comment.get("score", 0),
                            "created_utc": datetime.datetime.fromtimestamp(comment.get("created_utc", 0)),
                            "author": comment.get("author", "[deleted]"),
                            "is_submitter": comment.get("is_submitter", False),
                            "permalink": f"https://www.reddit.com{comment.get('permalink', '')}"
                        }

                        all_comments.append(comment_info)
                        comment_id += 1

                # Pausa para evitar lÃ­mites de tasa
                time.sleep(1)

            # Pausa entre subreddits
            time.sleep(2)

    # Convierte a DataFrames
    df_posts = pd.DataFrame(all_posts) if all_posts else pd.DataFrame()
    df_comments = pd.DataFrame(all_comments) if all_comments else pd.DataFrame()

    print(f"âœ… Se encontraron {len(df_posts)} posts y {len(df_comments)} comentarios.")

    return df_posts, df_comments

def clean_text(text):
    """Limpia el texto de caracteres especiales y formatos Reddit"""
    if not isinstance(text, str):
        return ""

    # Elimina URLs
    text = re.sub(r'http\S+', '', text)
    # Elimina caracteres de formato Reddit
    text = re.sub(r'\[|\]|\(|\)|\*|#|>', '', text)
    # Normaliza espacios
    text = re.sub(r'\s+', ' ', text).strip()

    return text

def save_to_csv(df, filename):
    """Guarda un DataFrame en un archivo CSV manejando errores de codificaciÃ³n"""
    if df.empty:
        print(f"No hay datos para guardar en {filename}")
        return False

    try:
        df.to_csv(filename, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)
        print(f"âœ… Datos guardados en {filename}")
        return True
    except Exception as e:
        print(f"Error guardando {filename}: {e}")
        # Intenta con otra codificaciÃ³n
        try:
            df.to_csv(filename, index=False, encoding='latin1', quoting=csv.QUOTE_ALL)
            print(f"âœ… Datos guardados en {filename} con codificaciÃ³n alternativa")
            return True
        except:
            print(f"âŒ No se pudo guardar {filename}")
            return False

def get_user_inputs():
    """Solicita al usuario las entradas necesarias para la extracciÃ³n de datos"""
    print("\n" + "="*60)
    print("ğŸ“Š EXTRACTOR DE DATOS DE REDDIT SOBRE ARANCELES COMERCIALES ğŸ“Š")
    print("="*60 + "\n")

    print("Para usar este script, necesitas las credenciales de una aplicaciÃ³n de Reddit.")
    print("Puedes crear una app en: https://www.reddit.com/prefs/apps\n")

    # Solicita credenciales
    client_id = input("ğŸ”‘ Client ID de tu app de Reddit: ").strip()
    client_secret = input("ğŸ”‘ Client Secret de tu app de Reddit: ").strip()

    # Solicita tÃ©rminos de bÃºsqueda
    default_terms = ["aranceles MÃ©xico", "aranceles CanadÃ¡", "Trump aranceles",
                     "25% arancel", "TMEC aranceles", "tariffs Mexico Canada"]

    print("\nTÃ©rminos de bÃºsqueda predeterminados:")
    for i, term in enumerate(default_terms, 1):
        print(f"  {i}. {term}")

    custom_terms = input("\nğŸ” Â¿Quieres usar tÃ©rminos personalizados? (s/n, default: n): ").strip().lower()

    if custom_terms == 's' or custom_terms == 'si' or custom_terms == 'sÃ­' or custom_terms == 'y' or custom_terms == 'yes':
        terms_input = input("ğŸ” Ingresa los tÃ©rminos separados por comas: ").strip()
        search_terms = [term.strip() for term in terms_input.split(',') if term.strip()]
        if not search_terms:
            print("âš ï¸ No se ingresaron tÃ©rminos vÃ¡lidos. Usando tÃ©rminos predeterminados.")
            search_terms = default_terms
    else:
        search_terms = default_terms

    # Solicita subreddits
    default_subreddits = "Economics+Politics+worldnews+news+business+mexico+canada+trade"

    custom_subreddits = input(f"\nğŸ“š Â¿Quieres usar subreddits personalizados? (s/n, default: n): ").strip().lower()

    if custom_subreddits == 's' or custom_subreddits == 'si' or custom_subreddits == 'sÃ­' or custom_subreddits == 'y' or custom_subreddits == 'yes':
        subreddits = input(f"ğŸ“š Ingresa los subreddits separados por '+': ").strip()
        if not subreddits:
            print("âš ï¸ No se ingresaron subreddits vÃ¡lidos. Usando subreddits predeterminados.")
            subreddits = default_subreddits
    else:
        subreddits = default_subreddits

    # LÃ­mites
    try:
        post_limit = int(input("\nğŸ“ NÃºmero mÃ¡ximo de posts por tÃ©rmino y subreddit (default: 25): ") or "25")
    except ValueError:
        post_limit = 25
        print("âš ï¸ Valor no vÃ¡lido. Usando 25 posts por tÃ©rmino y subreddit.")

    try:
        comment_limit = int(input("ğŸ’¬ NÃºmero mÃ¡ximo de comentarios por post (default: 20): ") or "20")
    except ValueError:
        comment_limit = 20
        print("âš ï¸ Valor no vÃ¡lido. Usando 20 comentarios por post.")

    return {
        "client_id": client_id,
        "client_secret": client_secret,
        "search_terms": search_terms,
        "subreddits": subreddits,
        "post_limit": post_limit,
        "comment_limit": comment_limit
    }

def main():
    # Obtener entradas del usuario
    inputs = get_user_inputs()

    print("\n" + "-"*60)
    print(f"ğŸš€ Iniciando extracciÃ³n de datos de Reddit desde r/{inputs['subreddits']}")
    print(f"ğŸ” Buscando {len(inputs['search_terms'])} tÃ©rminos: {', '.join(inputs['search_terms'])}")
    print("-"*60 + "\n")

    # Extrae los datos
    df_posts, df_comments = extract_reddit_data(
        client_id=inputs["client_id"],
        client_secret=inputs["client_secret"],
        search_terms=inputs["search_terms"],
        subreddits=inputs["subreddits"],
        post_limit=inputs["post_limit"],
        comment_limit=inputs["comment_limit"]
    )

    print(f"\nğŸ“Š ExtracciÃ³n completada:")
    print(f"Posts extraÃ­dos: {len(df_posts)}")
    print(f"Comentarios extraÃ­dos: {len(df_comments)}")

    # Limpia los textos si hay datos
    if not df_posts.empty:
        df_posts['title_clean'] = df_posts['title'].apply(clean_text)
        df_posts['text_clean'] = df_posts['text'].apply(clean_text)

    if not df_comments.empty:
        df_comments['text_clean'] = df_comments['text'].apply(clean_text)

    # Ruta especÃ­fica para guardar en Google Drive
    save_path = '/content/drive/MyDrive/Development/DataScience/Sentiment_Analysis'

    # Montar Google Drive si aÃºn no estÃ¡ montado
    try:
        from google.colab import drive
        drive.mount('/content/drive', force_remount=False)
        print("âœ… Google Drive montado correctamente")
    except:
        print("âš ï¸ No se pudo montar Google Drive o ya estaba montado")

    # Crear timestamp para los nombres de archivo
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")

    # Guardar los dataframes en la ruta especÃ­fica
    if not df_posts.empty:
        posts_filename = f"{save_path}/reddit_posts_aranceles_{timestamp}.csv"
        try:
            df_posts.to_csv(posts_filename, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)
            print(f"âœ… Posts guardados en: {posts_filename}")
        except Exception as e:
            print(f"âŒ Error guardando posts: {e}")

    if not df_comments.empty:
        comments_filename = f"{save_path}/reddit_comments_aranceles_{timestamp}.csv"
        try:
            df_comments.to_csv(comments_filename, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)
            print(f"âœ… Comentarios guardados en: {comments_filename}")
        except Exception as e:
            print(f"âŒ Error guardando comentarios: {e}")

    print("\nâœ… Proceso completado.")

if __name__ == "__main__":
    main()